{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=8>Sentiment Analysis</font>\n",
    "<br><br>\n",
    "本篇文章主要用神经网络中三种最基本的神经网络dnn、rnn以及cnn构建情感分类模型，并比较和分析不同模型的优劣。具体而言本文分为四个部分:\n",
    "\n",
    "- 数据处理\n",
    "- DNN模型\n",
    "- RNN模型\n",
    "- CNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named tensorflow",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b8ddb312b66e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named tensorflow"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['glove.6B.300d.txt', '.DS_Store', 'neg.txt', 'pos.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 加载正负评论数据\n",
    "# pos数据\n",
    "with open(\"data/pos.txt\", \"r\") as f:\n",
    "    pos_text = f.read()\n",
    "\n",
    "# neg数据\n",
    "with open(\"data/neg.txt\", \"r\") as f:\n",
    "    neg_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 描述性统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- POSITIVE TEXT --------------------\n",
      "Total positive sentences: 5331\n",
      "The average length of positive sentences: 21.0921027949728\n",
      "The max length of positive sentences: 59\n",
      "The min length of positive sentences: 2\n",
      "Most common words in positive sentences: \n",
      "[('.', 6972), (',', 5268), ('the', 5051), ('a', 3830), ('and', 3548), ('of', 3311), ('to', 1969), ('is', 1707), ('in', 1338), ('that', 1262), ('it', 1100), ('with', 883), ('as', 879), ('film', 822), ('but', 782), ('an', 754), ('its', 699), ('for', 673), ('this', 666), (\"it's\", 564), ('movie', 510), ('you', 494), ('on', 424), ('be', 419), ('by', 380), ('has', 379), ('not', 367), ('one', 366), ('at', 366), ('about', 363), ('from', 349), ('are', 348), ('his', 344), ('\"', 330), ('--', 319), ('more', 311), ('all', 289), ('than', 282), ('like', 281), ('if', 264), ('have', 259), ('story', 256), ('who', 247), ('most', 240), ('what', 225), ('into', 213), ('so', 209), ('will', 199), ('good', 198), ('comedy', 192), ('or', 189), ('i', 181), ('funny', 181), ('even', 180), ('out', 178), ('their', 175), ('best', 166), ('can', 166), ('some', 164), ('way', 164), ('time', 158), ('us', 156), ('much', 154), ('up', 154), ('make', 151), ('love', 149), ('just', 148), ('makes', 144), ('life', 144), ('characters', 144), ('may', 141), ('work', 139), ('performances', 138), ('your', 135), ('very', 135), ('little', 129), ('enough', 127), ('while', 123), ('her', 123), ('no', 120), ('still', 120), ('director', 119), ('look', 119), ('there', 118), ('well', 117), ('both', 114), ('fun', 113), ('movies', 111), ('drama', 111), ('new', 110), ('never', 110), ('those', 109), ('films', 109), ('we', 108), ('when', 107), ('great', 105), ('(', 104), (')', 104), ('which', 104), ('only', 103)]\n",
      "\n",
      "-------------------- NEGATIVE TEXT --------------------\n",
      "Total negative sentences: 5331\n",
      "The average length of negative sentences: 20.93884824610767\n",
      "The max length of negative sentences: 56\n",
      "The min length of negative sentences: 1\n",
      "Most common words in negative sentences: \n",
      "[('.', 7038), ('the', 5045), (',', 4769), ('a', 3451), ('of', 2750), ('and', 2647), ('to', 2264), ('is', 1660), ('in', 1290), ('that', 1208), ('it', 1181), ('as', 922), ('but', 855), ('this', 774), ('for', 763), ('movie', 758), ('with', 677), ('its', 636), ('film', 623), ('an', 567), (\"it's\", 555), ('be', 520), ('on', 471), ('like', 439), ('not', 436), ('more', 416), ('by', 415), ('you', 398), ('than', 382), ('about', 370), ('too', 365), ('have', 364), ('one', 361), ('are', 360), ('all', 352), ('so', 346), ('at', 339), ('or', 330), ('has', 330), ('\"', 325), ('from', 324), ('--', 310), ('just', 290), ('i', 285), ('his', 284), ('if', 273), ('no', 267), ('much', 232), ('up', 222), ('story', 220), ('out', 220), ('bad', 206), ('only', 205), ('into', 204), ('even', 202), ('what', 188), ('who', 185), ('time', 181), ('good', 179), ('will', 175), ('little', 173), ('can', 171), ('some', 170), ('been', 169), ('characters', 169), ('?', 167), ('most', 162), ('comedy', 161), ('when', 155), (\"doesn't\", 153), ('never', 152), ('would', 148), ('was', 143), ('enough', 140), ('which', 137), (\"there's\", 137), ('he', 137), ('there', 132), ('way', 132), ('very', 130), ('really', 130), ('your', 129), ('any', 128), ('make', 127), (':', 124), (')', 124), ('they', 123), ('(', 122), ('nothing', 121), ('plot', 120), ('their', 117), (\"isn't\", 116), ('should', 116), ('could', 115), ('every', 114), ('something', 113), ('director', 112), ('made', 109), ('we', 109), ('through', 108)]\n"
     ]
    }
   ],
   "source": [
    "# 积极文本统计\n",
    "print(\"-\" * 20 + \" POSITIVE TEXT \" + \"-\" * 20)\n",
    "# 分句\n",
    "pos_sentences = pos_text.lower().split(\"\\n\")\n",
    "print(\"Total positive sentences: {}\".format(len(pos_sentences)))\n",
    "print(\"The average length of positive sentences: {}\".format(np.mean([len(sentence.split()) for sentence in pos_sentences])))\n",
    "print(\"The max length of positive sentences: {}\".format(np.max([len(sentence.split()) for sentence in pos_sentences])))\n",
    "print(\"The min length of positive sentences: {}\".format(np.min([len(sentence.split()) for sentence in pos_sentences])))\n",
    "# 统计高频词\n",
    "c = Counter(pos_text.split()).most_common(100)\n",
    "print(\"Most common words in positive sentences: \\n{}\".format(c))\n",
    "\n",
    "# 校级文本统计\n",
    "print()\n",
    "print(\"-\" * 20 + \" NEGATIVE TEXT \" + \"-\" * 20)\n",
    "# 分句\n",
    "neg_sentences = neg_text.lower().split(\"\\n\")\n",
    "print(\"Total negative sentences: {}\".format(len(neg_sentences)))\n",
    "print(\"The average length of negative sentences: {}\".format(np.mean([len(sentence.split()) for sentence in neg_sentences])))\n",
    "print(\"The max length of negative sentences: {}\".format(np.max([len(sentence.split()) for sentence in neg_sentences])))\n",
    "print(\"The min length of negative sentences: {}\".format(np.min([len(sentence.split()) for sentence in neg_sentences])))\n",
    "# 统计高频词\n",
    "c = Counter(neg_text.split()).most_common(100)\n",
    "print(\"Most common words in negative sentences: \\n{}\".format(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "\n",
    "- 构造词典Vocabulary\n",
    "- 构造映射表\n",
    "- 转换单词为tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 句子最大长度\n",
    "SENTENCE_LIMIT_SIZE = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造词典\n",
    "\n",
    "我们要基于整个语料来构造我们的词典，由于文本中包含许多干扰词汇，例如仅出现过1次的这类单词。对于这类极其低频词汇，我们可以对其进行去除，一方面能加快模型执行效率，一方面也能减少特殊词带来的噪声。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 合并pos和neg文本\n",
    "total_text = pos_text + \"\\n\" + neg_text\n",
    "# 统计词汇\n",
    "c = Counter(total_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"century's\", 1),\n",
       " ('jean-claud', 1),\n",
       " ('segal', 1),\n",
       " ('middle-earth', 1),\n",
       " ('too-tepid', 1),\n",
       " ('showed', 1),\n",
       " ('curls', 1),\n",
       " ('fed', 1),\n",
       " ('ponders', 1),\n",
       " (\"it'\", 1),\n",
       " ('enrapturing', 1),\n",
       " ('tempt', 1),\n",
       " ('inscrutable', 1),\n",
       " ('spiderman', 1),\n",
       " ('latent', 1),\n",
       " ('gangsta', 1),\n",
       " ('shook', 1),\n",
       " ('rattled', 1),\n",
       " ('deceptive', 1),\n",
       " ('grimness', 1),\n",
       " ('fatalist', 1),\n",
       " ('worldview', 1),\n",
       " ('lobbies', 1),\n",
       " ('two-lane', 1),\n",
       " ('roadside', 1),\n",
       " ('cafes', 1),\n",
       " ('permeate', 1),\n",
       " ('bona-fide', 1),\n",
       " ('outings', 1),\n",
       " ('cartoonlike', 1),\n",
       " ('magnet', 1),\n",
       " ('co-star', 1),\n",
       " (\"'compleja\", 1),\n",
       " ('intelectualmente', 1),\n",
       " ('retadora', 1),\n",
       " ('ladrón', 1),\n",
       " ('orquídeas', 1),\n",
       " ('esos', 1),\n",
       " ('filmes', 1),\n",
       " ('precisamente', 1),\n",
       " ('originalidad', 1),\n",
       " ('karmen', 1),\n",
       " ('chanting', 1),\n",
       " ('braided', 1),\n",
       " ('wipe', 1),\n",
       " ('jeweled', 1),\n",
       " ('beads', 1),\n",
       " ('lacerating', 1),\n",
       " (\"'50's\", 1),\n",
       " ('cheesiness', 1),\n",
       " (\"johnson's\", 1),\n",
       " ('orchestrates', 1),\n",
       " ('siberian', 1),\n",
       " ('sheep', 1),\n",
       " ('hosts', 1),\n",
       " ('parka-wrapped', 1),\n",
       " ('everytime', 1),\n",
       " ('singer/composer', 1),\n",
       " ('contributes', 1),\n",
       " ('slew', 1),\n",
       " ('intrusive', 1),\n",
       " ('enlightened', 1),\n",
       " (\"derrida's\", 1),\n",
       " (\"1998's\", 1),\n",
       " ('chiaroscuro', 1),\n",
       " ('uncontrolled', 1),\n",
       " ('farther', 1),\n",
       " ('quietness', 1),\n",
       " ('domineering', 1),\n",
       " (\"mother's\", 1),\n",
       " ('shadings', 1),\n",
       " ('coloring', 1),\n",
       " ('treebeard', 1),\n",
       " (\"'performance'\", 1),\n",
       " ('ingeniously', 1),\n",
       " ('aberration', 1),\n",
       " ('originally', 1),\n",
       " ('comedy/thriller', 1),\n",
       " ('orchestrate', 1),\n",
       " ('overpraised', 1),\n",
       " ('catchy', 1),\n",
       " ('spycraft', 1),\n",
       " (\"damon's\", 1),\n",
       " ('katz', 1),\n",
       " ('lynchings', 1),\n",
       " ('reel-to-reel', 1),\n",
       " ('recordings', 1),\n",
       " ('meeropol', 1),\n",
       " ('anthropologically', 1),\n",
       " (\"early-'80s\", 1),\n",
       " ('suburbia', 1),\n",
       " ('interstitial', 1),\n",
       " ('vertiginous', 1),\n",
       " ('embers', 1),\n",
       " ('dormant', 1),\n",
       " ('calcified', 1),\n",
       " ('chronic', 1),\n",
       " (\"irwin's\", 1),\n",
       " ('hemmingway', 1),\n",
       " ('accelerated', 1),\n",
       " ('lovers-on-the-run', 1),\n",
       " (\"piesiewicz's\", 1),\n",
       " ('veronique', 1),\n",
       " ('again-courage', 1),\n",
       " ('sl2', 1),\n",
       " ('self-contained', 1),\n",
       " ('pabst', 1),\n",
       " ('ribbon', 1),\n",
       " ('du', 1),\n",
       " ('sarcasm', 1),\n",
       " ('quizzical', 1),\n",
       " ('syncopated', 1),\n",
       " ('mimicking', 1),\n",
       " ('memory-as-identity', 1),\n",
       " ('obviation', 1),\n",
       " ('long-held', 1),\n",
       " ('illusions', 1),\n",
       " ('erasing', 1),\n",
       " ('recasts', 1),\n",
       " ('gambol', 1),\n",
       " ('fluidly', 1),\n",
       " ('b-scene', 1),\n",
       " ('digital-video', 1),\n",
       " ('comedians', 1),\n",
       " (\"'truth'\", 1),\n",
       " ('deconstructing', 1),\n",
       " ('blessing', 1),\n",
       " ('thunderous', 1),\n",
       " ('cadences', 1),\n",
       " ('shortage', 1),\n",
       " ('responsive', 1),\n",
       " ('koreans', 1),\n",
       " ('gourmet', 1),\n",
       " ('drive-thru', 1),\n",
       " ('strap', 1),\n",
       " ('frontier', 1),\n",
       " ('logistical', 1),\n",
       " ('milestone', 1),\n",
       " ('[schweiger', 1),\n",
       " ('steak', 1),\n",
       " ('minefield', 1),\n",
       " ('gorefests', 1),\n",
       " ('connoisseur', 1),\n",
       " ('lo-fi', 1),\n",
       " ('15-cent', 1),\n",
       " ('stump', 1),\n",
       " ('hogs', 1),\n",
       " ('conan-esque', 1),\n",
       " ('partially', 1),\n",
       " ('minty', 1),\n",
       " ('prizes', 1),\n",
       " ('rambunctious', 1),\n",
       " ('non-jew', 1),\n",
       " ('happiest', 1),\n",
       " ('[but', 1),\n",
       " (\"it's]\", 1),\n",
       " ('backs', 1),\n",
       " ('commodity', 1),\n",
       " ('homespun', 1),\n",
       " ('mule', 1),\n",
       " ('skinner', 1),\n",
       " ('posse', 1),\n",
       " ('seaworthy', 1),\n",
       " ('sock-you-in-the-eye', 1),\n",
       " ('non-reactionary', 1),\n",
       " ('near-disaster', 1),\n",
       " ('makmalbaf', 1),\n",
       " ('kurdish', 1),\n",
       " ('borderlands', 1),\n",
       " ('chunk', 1),\n",
       " ('pinch', 1),\n",
       " ('tartness', 1),\n",
       " ('tribulations', 1),\n",
       " (\"comedy'\", 1),\n",
       " (\"willams'\", 1),\n",
       " ('ebb', 1),\n",
       " ('deposits', 1),\n",
       " ('[jack', 1),\n",
       " (\"nicholson's]\", 1),\n",
       " ('20-year-old', 1),\n",
       " ('exhilarate', 1),\n",
       " ('beanie', 1),\n",
       " ('ever-escalating', 1),\n",
       " ('latifah', 1),\n",
       " ('flaunting', 1),\n",
       " ('actor/director', 1),\n",
       " ('giles', 1),\n",
       " ('nuttgens', 1),\n",
       " ('contradictions', 1),\n",
       " ('lump-in-the-throat', 1),\n",
       " ('diverted', 1),\n",
       " ('lightens', 1),\n",
       " ('bigger-than-life', 1),\n",
       " ('questing', 1),\n",
       " ('racked', 1),\n",
       " ('genet', 1),\n",
       " ('rechy', 1),\n",
       " ('fassbinder', 1),\n",
       " ('nocturnal', 1),\n",
       " ('goya', 1),\n",
       " ('badge', 1),\n",
       " ('permutations', 1),\n",
       " ('[drumline]', 1),\n",
       " ('headlines', 1),\n",
       " ('1995', 1),\n",
       " ('disapproval', 1),\n",
       " ('tinge', 1),\n",
       " ('crystalline', 1),\n",
       " ('three-year-old', 1),\n",
       " ('fictionalize', 1),\n",
       " ('visits', 1),\n",
       " ('slice-of-depression', 1),\n",
       " ('grasped', 1),\n",
       " ('composing', 1),\n",
       " ('preteens', 1),\n",
       " (\"o's\", 1),\n",
       " ('knock-offs', 1),\n",
       " ('political-action', 1),\n",
       " ('fastidiousness', 1),\n",
       " ('ellefsen', 1),\n",
       " ('frailties', 1),\n",
       " ('magnified', 1),\n",
       " ('vex', 1),\n",
       " (\"petin's\", 1),\n",
       " ('penetrates', 1),\n",
       " ('tantalizing', 1),\n",
       " ('provocatuers', 1),\n",
       " ('aroused', 1),\n",
       " ('mideast', 1),\n",
       " ('perceptively', 1),\n",
       " ('jirí', 1),\n",
       " (\"hubac's\", 1),\n",
       " ('silberstein', 1),\n",
       " ('additional', 1),\n",
       " ('shapelessly', 1),\n",
       " ('gratifying', 1),\n",
       " ('appraisal', 1),\n",
       " ('anti-date', 1),\n",
       " ('intently', 1),\n",
       " ('regimes', 1),\n",
       " ('figurative', 1),\n",
       " ('port-of-call', 1),\n",
       " ('even-handed', 1),\n",
       " ('dock', 1),\n",
       " ('unloading', 1),\n",
       " ('greek-american', 1),\n",
       " ('testify', 1),\n",
       " ('comparative', 1),\n",
       " ('inhabited', 1),\n",
       " ('venomous', 1),\n",
       " ('bigotries', 1),\n",
       " ('theocracy', 1),\n",
       " ('antithesis', 1),\n",
       " ('dazzlingly', 1),\n",
       " (\"münch's\", 1),\n",
       " ('overindulgence', 1),\n",
       " ('deteriorating', 1),\n",
       " ('croc', 1),\n",
       " ('disrupts', 1),\n",
       " ('re-enactments', 1),\n",
       " ('character-based', 1),\n",
       " ('endearingly', 1),\n",
       " ('post-soviet', 1),\n",
       " ('russia', 1),\n",
       " ('bishop', 1),\n",
       " ('standouts', 1),\n",
       " ('bastions', 1),\n",
       " ('ikea', 1),\n",
       " ('blurred', 1),\n",
       " ('razor', 1),\n",
       " ('transferral', 1),\n",
       " ('spy-on-the-run', 1),\n",
       " ('sanded', 1),\n",
       " ('microcosm', 1),\n",
       " ('dabbling', 1),\n",
       " ('authors', 1),\n",
       " ('battista', 1),\n",
       " ('directress', 1),\n",
       " ('breezily', 1),\n",
       " ('apolitical', 1),\n",
       " ('gawk', 1),\n",
       " ('wallpaper', 1),\n",
       " ('hu', 1),\n",
       " ('matter-of-fact', 1),\n",
       " ('glint', 1),\n",
       " ('raja', 1),\n",
       " ('enthuse', 1),\n",
       " (\"andersson's\", 1),\n",
       " ('rigorous', 1),\n",
       " ('distancing', 1),\n",
       " ('real-live', 1),\n",
       " ('movingly', 1),\n",
       " ('179-minute', 1),\n",
       " ('institution--acted', 1),\n",
       " ('weakened', 1),\n",
       " ('supportive', 1),\n",
       " ('40-minute', 1),\n",
       " ('valedictory', 1),\n",
       " ('bargain', 1),\n",
       " ('shards', 1),\n",
       " ('gyro', 1),\n",
       " (\"'bartleby'\", 1),\n",
       " ('farrell', 1),\n",
       " ('foil', 1),\n",
       " (\"willis's\", 1),\n",
       " ('world-weary', 1),\n",
       " ('colonel', 1),\n",
       " ('conditioned', 1),\n",
       " ('saucer-eyed', 1),\n",
       " ('downy-cheeked', 1),\n",
       " ('moppets', 1),\n",
       " ('sugar-free', 1),\n",
       " ('post-breakup', 1),\n",
       " (\"sayles'\", 1),\n",
       " ('wordplay', 1),\n",
       " ('preference', 1),\n",
       " ('indomitable', 1),\n",
       " ('ostentatious', 1),\n",
       " (\"african-american's\", 1),\n",
       " ('randy', 1),\n",
       " ('figuratively', 1),\n",
       " ('[sex', 1),\n",
       " ('lucía]', 1),\n",
       " ('arousing', 1),\n",
       " ('andré', 1),\n",
       " ('turpin', 1),\n",
       " (\"renner's\", 1),\n",
       " ('award-worthy', 1),\n",
       " ('rhythmic', 1),\n",
       " ('adulthood', 1),\n",
       " ('fraught', 1),\n",
       " ('wannabes', 1),\n",
       " ('addessi', 1),\n",
       " ('beatrice', 1),\n",
       " (\"jones'\", 1),\n",
       " ('melding', 1),\n",
       " ('reflecting', 1),\n",
       " ('heartbeat-like', 1),\n",
       " ('whole-heartedly', 1),\n",
       " ('movie--', 1),\n",
       " ('longley', 1),\n",
       " ('horrifically', 1),\n",
       " (\"crowd-pleaser's\", 1),\n",
       " ('gruelling', 1),\n",
       " (\"wollter's\", 1),\n",
       " ('euro-film', 1),\n",
       " ('rockwell', 1),\n",
       " ('vastness', 1),\n",
       " ('green-guts', 1),\n",
       " ('beaut', 1),\n",
       " ('bundy', 1),\n",
       " ('reilly', 1),\n",
       " ('octopus', 1),\n",
       " ('deceivingly', 1),\n",
       " ('retrospect', 1),\n",
       " ('ana', 1),\n",
       " ('[anderson]', 1),\n",
       " ('ho-tep', 1),\n",
       " ('likability', 1),\n",
       " ('increments', 1),\n",
       " ('camouflaged', 1),\n",
       " (\"'brazil\", 1),\n",
       " ('goddammit', 1),\n",
       " ('adoration', 1),\n",
       " ('hogwarts', 1),\n",
       " ('mischief', 1),\n",
       " ('heart-on-its-sleeve', 1),\n",
       " ('redgrave', 1),\n",
       " ('aquatic', 1),\n",
       " ('baja', 1),\n",
       " ('peninsula', 1),\n",
       " ('mexico', 1),\n",
       " ('hyper-time', 1),\n",
       " ('grenier', 1),\n",
       " ('heidegger-', 1),\n",
       " ('nietzsche-referencing', 1),\n",
       " ('patois', 1),\n",
       " ('mullinski', 1),\n",
       " ('compact', 1),\n",
       " ('breezes', 1),\n",
       " ('imagining', 1),\n",
       " ('sardine', 1),\n",
       " (\"'face\", 1),\n",
       " (\"value'\", 1),\n",
       " ('wimp', 1),\n",
       " ('cried', 1),\n",
       " ('heart-affecting', 1),\n",
       " ('displayed', 1),\n",
       " ('33-year-old', 1),\n",
       " ('inexperience', 1),\n",
       " ('division', 1),\n",
       " ('risk-takers', 1),\n",
       " ('sandwiched', 1),\n",
       " ('heart-rending', 1),\n",
       " ('buzz-obsessed', 1),\n",
       " ('descend', 1),\n",
       " ('utah', 1),\n",
       " ('ferret', 1),\n",
       " (\"'tadpole'\", 1),\n",
       " ('declared', 1),\n",
       " (\"elliott's\", 1),\n",
       " ('fashions', 1),\n",
       " ('character-', 1),\n",
       " ('and-', 1),\n",
       " ('connects', 1),\n",
       " ('double-crosses', 1),\n",
       " ('ranging', 1),\n",
       " ('gathers', 1),\n",
       " (\"l'avventura\", 1),\n",
       " ('repulsion', 1),\n",
       " ('congeals', 1),\n",
       " ('tingle', 1),\n",
       " (\"'barbershop'\", 1),\n",
       " ('anytime', 1),\n",
       " ('narcotizing', 1),\n",
       " ('ensnaring', 1),\n",
       " ('[taymor]', 1),\n",
       " ('utilizes', 1),\n",
       " ('catapulting', 1),\n",
       " ('eye-opening', 1),\n",
       " ('oblivion', 1),\n",
       " ('examined', 1),\n",
       " (\"villeneuve's\", 1),\n",
       " ('sugar-coating', 1),\n",
       " ('[villeneuve]', 1),\n",
       " ('intuitively', 1),\n",
       " ('squalor', 1),\n",
       " ('bared', 1),\n",
       " ('confronted', 1),\n",
       " ('code-talk', 1),\n",
       " ('out-stealth', 1),\n",
       " ('precollegiate', 1),\n",
       " ('liberated', 1),\n",
       " (\"hogan's\", 1),\n",
       " (\"reno's\", 1),\n",
       " ('suffused', 1),\n",
       " ('trumpets', 1),\n",
       " ('go-round', 1),\n",
       " ('headlong', 1),\n",
       " ('delinquent', 1),\n",
       " ('peter/spider-man', 1),\n",
       " ('myths', 1),\n",
       " ('afresh', 1),\n",
       " ('arouse', 1),\n",
       " ('unknowing', 1),\n",
       " ('[sinks]', 1),\n",
       " ('resolute', 1),\n",
       " ('nakedness', 1),\n",
       " ('interwoven…', 1),\n",
       " ('positions', 1),\n",
       " ('stimulates', 1),\n",
       " ('unobtrusively', 1),\n",
       " (\"version's\", 1),\n",
       " ('plentiful', 1),\n",
       " ('provide[s]', 1),\n",
       " ('technology-of-the-moment', 1),\n",
       " ('manipulate', 1),\n",
       " ('saturation', 1),\n",
       " (\"glass'\", 1),\n",
       " ('divining', 1),\n",
       " ('confirmation', 1),\n",
       " ('unelected', 1),\n",
       " ('incurious', 1),\n",
       " ('uncharismatic', 1),\n",
       " ('overgrown', 1),\n",
       " ('whiplash', 1),\n",
       " ('time-honored', 1),\n",
       " ('bowel-curdling', 1),\n",
       " ('heart-stopping', 1),\n",
       " ('unmentioned', 1),\n",
       " ('amalgamating', 1),\n",
       " ('not-so-stock', 1),\n",
       " ('super-cool', 1),\n",
       " ('relax', 1),\n",
       " ('undoubted', 1),\n",
       " ('extensions', 1),\n",
       " ('charmers', 1),\n",
       " ('pencil-thin', 1),\n",
       " ('pro-fat', 1),\n",
       " ('sparklingly', 1),\n",
       " ('consciousness-raiser', 1),\n",
       " ('bonehead', 1),\n",
       " ('deciding', 1),\n",
       " ('affirmation', 1),\n",
       " ('good-deed/bad-deed', 1),\n",
       " ('reversals', 1),\n",
       " ('sinner', 1),\n",
       " ('symmetrical', 1),\n",
       " ('cross-shaped', 1),\n",
       " ('unaccustomed', 1),\n",
       " ('contests', 1),\n",
       " (\"griffin's\", 1),\n",
       " ('testimonials', 1),\n",
       " ('arena', 1),\n",
       " ('barrett', 1),\n",
       " ('browning', 1),\n",
       " ('hmm', 1),\n",
       " ('800-page', 1),\n",
       " ('nurturing', 1),\n",
       " ('gauzy', 1),\n",
       " ('dithering', 1),\n",
       " ('zigs', 1),\n",
       " ('zags', 1),\n",
       " ('laser-projected', 1),\n",
       " ('spell-casting', 1),\n",
       " ('dreyfus', 1),\n",
       " ('grader', 1),\n",
       " ('b-minus', 1),\n",
       " ('patterns', 1),\n",
       " ('ideals', 1),\n",
       " ('fatality', 1),\n",
       " ('classism', 1),\n",
       " ('ignorance', 1),\n",
       " ('meat-and-potatoes', 1),\n",
       " ('shticks', 1),\n",
       " ('sympathetically', 1),\n",
       " ('[gai]', 1),\n",
       " ('personifying', 1),\n",
       " ('intimidating', 1),\n",
       " ('horror/thriller', 1),\n",
       " ('well-known', 1),\n",
       " ('blobby', 1),\n",
       " ('superlarge', 1),\n",
       " ('changer', 1),\n",
       " ('self-evaluation', 1),\n",
       " ('guidance', 1),\n",
       " ('invade', 1),\n",
       " ('mindsets', 1),\n",
       " ('fanatically', 1),\n",
       " ('fetishized', 1),\n",
       " ('old-movie', 1),\n",
       " ('idiosyncrasy', 1),\n",
       " ('monastic', 1),\n",
       " ('peter]', 1),\n",
       " ('majesty', 1),\n",
       " ('slipper', 1),\n",
       " ('holidays', 1),\n",
       " ('incarnates', 1),\n",
       " ('prophetic', 1),\n",
       " ('exacting', 1),\n",
       " ('patronized', 1),\n",
       " ('crafts', 1),\n",
       " ('‘what', 1),\n",
       " (\"see'\", 1),\n",
       " ('incandescent', 1),\n",
       " ('stupendous', 1),\n",
       " ('unsettling--but', 1),\n",
       " ('unquestionably', 1),\n",
       " ('13-year-old', 1),\n",
       " ('bedouins', 1),\n",
       " ('wide-ranging', 1),\n",
       " ('non-shakespeare', 1),\n",
       " ('softest', 1),\n",
       " ('revolt', 1),\n",
       " ('off-the-cuff', 1),\n",
       " ('gunning', 1),\n",
       " (\"bow's\", 1),\n",
       " ('preschool', 1),\n",
       " ('good-humored', 1),\n",
       " ('charmingly', 1),\n",
       " ('bola', 1),\n",
       " ('peeved', 1),\n",
       " ('nalin', 1),\n",
       " ('crime-film', 1),\n",
       " ('loosey-goosey', 1),\n",
       " ('is…', 1),\n",
       " ('destinees', 1),\n",
       " ('bedevils', 1),\n",
       " ('77-minute', 1),\n",
       " ('40-year-old', 1),\n",
       " ('soldier', 1),\n",
       " ('45-minute', 1),\n",
       " ('teamwork', 1),\n",
       " ('molony', 1),\n",
       " ('parisian', 1),\n",
       " ('pg-rated', 1),\n",
       " ('ensnared', 1),\n",
       " ('ferocious', 1),\n",
       " ('gosh', 1),\n",
       " ('quests', 1),\n",
       " ('courting', 1),\n",
       " ('preposterousness', 1),\n",
       " ('interference', 1),\n",
       " ('margolo', 1),\n",
       " ('computer-animated', 1),\n",
       " ('self-actualization', 1),\n",
       " ('continental', 1),\n",
       " ('divides', 1),\n",
       " ('profiles', 1),\n",
       " (\"another's\", 1),\n",
       " ('screen-eating', 1),\n",
       " ('dominatrixes', 1),\n",
       " ('tango', 1),\n",
       " ('camera-work', 1),\n",
       " ('characterizing', 1),\n",
       " ('knots', 1),\n",
       " ('mock-tarantino', 1),\n",
       " ('scuzbag', 1),\n",
       " ('delicacy', 1),\n",
       " ('surpassed', 1),\n",
       " ('empress', 1),\n",
       " (\"leoni's\", 1),\n",
       " ('ellie', 1),\n",
       " ('recapturing', 1),\n",
       " ('pauses', 1),\n",
       " ('locked', 1),\n",
       " ('cat-and-cat', 1),\n",
       " (\"herek's\", 1),\n",
       " ('bottles', 1),\n",
       " (\"hornby's\", 1),\n",
       " ('drop-dead', 1),\n",
       " ('idoosyncratic', 1),\n",
       " ('terrain', 1),\n",
       " ('flatula', 1),\n",
       " ('advises', 1),\n",
       " ('denlopp', 1),\n",
       " ('deckhand', 1),\n",
       " ('updatings', 1),\n",
       " (\"silver's\", 1),\n",
       " ('parrot', 1),\n",
       " ('mimics', 1),\n",
       " (\"trio's\", 1),\n",
       " (\"niccol's\", 1),\n",
       " ('anti-hollywood', 1),\n",
       " (\"screenplay's\", 1),\n",
       " ('sappier', 1),\n",
       " (\"hook's\", 1),\n",
       " ('assuredness', 1),\n",
       " ('uninhibited', 1),\n",
       " ('pigeonhole-resisting', 1),\n",
       " ('antidotes', 1),\n",
       " ('11-year-old', 1),\n",
       " ('convert', 1),\n",
       " ('elmer', 1),\n",
       " (\"bernstein's\", 1),\n",
       " ('melodic', 1),\n",
       " ('10-inch', 1),\n",
       " ('edge-of-your-seat', 1),\n",
       " ('shambling', 1),\n",
       " ('custom-made', 1),\n",
       " ('hornby', 1),\n",
       " ('belated', 1),\n",
       " ('all-stars', 1),\n",
       " (\"ride's\", 1),\n",
       " ('lap', 1),\n",
       " ('gotta', 1),\n",
       " (\"carion's\", 1),\n",
       " ('hums', 1),\n",
       " ('buena', 1),\n",
       " ('oportunidad', 1),\n",
       " ('cultura', 1),\n",
       " ('aunque', 1),\n",
       " ('condensada', 1),\n",
       " ('aprovechar', 1),\n",
       " ('dyspeptic', 1),\n",
       " ('visualmente', 1),\n",
       " ('espectacular', 1),\n",
       " ('entretenida', 1),\n",
       " ('te', 1),\n",
       " ('sorprenderá', 1),\n",
       " ('theirs', 1),\n",
       " ('mirth', 1),\n",
       " ('frisky', 1),\n",
       " ('exporing', 1),\n",
       " ('chin', 1),\n",
       " ('marketplace', 1),\n",
       " ('amusingly', 1),\n",
       " (\"anymore'\", 1),\n",
       " ('shading', 1),\n",
       " ('[fessenden]', 1),\n",
       " (\"ross's\", 1),\n",
       " ('specials', 1),\n",
       " ('entrancing', 1),\n",
       " ('darn', 1),\n",
       " ('smarty-pants', 1),\n",
       " ('agreeable', 1),\n",
       " ('time-wasting', 1),\n",
       " (\"pal's\", 1),\n",
       " ('heartbeat', 1),\n",
       " ('inequities', 1),\n",
       " ('immorality', 1),\n",
       " ('administration', 1),\n",
       " ('misperception', 1),\n",
       " ('shinya', 1),\n",
       " (\"tsukamoto's\", 1),\n",
       " ('180', 1),\n",
       " ('fiascoes', 1),\n",
       " ('opera-to-film', 1),\n",
       " ('heaving', 1),\n",
       " ('love-jealousy-', 1),\n",
       " ('murder-suicide', 1),\n",
       " ('fandango', 1),\n",
       " ('abbas', 1),\n",
       " (\"'charly'\", 1),\n",
       " ('befuddlement', 1),\n",
       " ('marvellous', 1),\n",
       " ('mind-blowing', 1),\n",
       " ('breath-taking', 1),\n",
       " ('earthshaking', 1),\n",
       " ('fluctuating', 1),\n",
       " ('humanitarian', 1),\n",
       " (\"'co-stars\", 1),\n",
       " ('unlucky', 1),\n",
       " ('cassette', 1),\n",
       " ('def', 1),\n",
       " (\"leppard's\", 1),\n",
       " ('pyromania', 1),\n",
       " ('fandom', 1),\n",
       " ('combo', 1),\n",
       " ('closeness', 1),\n",
       " ('unreality', 1),\n",
       " ('broken-down', 1),\n",
       " ('andersson', 1),\n",
       " ('hoops', 1),\n",
       " ('plump', 1),\n",
       " ('fulsome', 1),\n",
       " ('reinforced', 1),\n",
       " ('all-ages', 1),\n",
       " ('quantum', 1),\n",
       " ('slash-dash', 1),\n",
       " ('potholes', 1),\n",
       " ('befall', 1),\n",
       " ('brethren', 1),\n",
       " ('turfs', 1),\n",
       " ('self-made', 1),\n",
       " ('low-down', 1),\n",
       " ('reviewing', 1),\n",
       " ('obscurities', 1),\n",
       " ('slam-bam', 1),\n",
       " ('miniscule', 1),\n",
       " ('bleep', 1),\n",
       " ('capturou', 1),\n",
       " ('pomo', 1),\n",
       " ('ouro', 1),\n",
       " ('well-oiled', 1),\n",
       " ('upholstered', 1),\n",
       " ('sickness', 1),\n",
       " ('rara', 1),\n",
       " ('avis', 1),\n",
       " ('articulated', 1),\n",
       " ('flights', 1),\n",
       " ('utmost', 1),\n",
       " ('economy', 1),\n",
       " ('samantha', 1),\n",
       " ('viewfinder', 1),\n",
       " (\"master's\", 1),\n",
       " ('sarcástica', 1),\n",
       " ('demencial', 1),\n",
       " ('predecesora', 1),\n",
       " ('ejemplo', 1),\n",
       " ('entretenimiento', 1),\n",
       " ('puro', 1),\n",
       " ('complejos', 1),\n",
       " (\"obsessive-compulsive's\", 1),\n",
       " ('cadness', 1),\n",
       " ('westfeldt', 1),\n",
       " ('juergensen', 1),\n",
       " ('israeli-occupied', 1),\n",
       " ('territories', 1),\n",
       " ('crit', 1),\n",
       " (\"'types'\", 1),\n",
       " ('elizabethan', 1),\n",
       " ('shagster', 1),\n",
       " ('casey', 1),\n",
       " ('kasem-furnished', 1),\n",
       " ('amongst', 1),\n",
       " ('self-interest', 1),\n",
       " ('representations', 1),\n",
       " ('contacts', 1),\n",
       " (\"'hosts'\", 1),\n",
       " (\"'guests\", 1),\n",
       " ('tastes', 1),\n",
       " ('foreboding', 1),\n",
       " ('jazzes', 1),\n",
       " ('madame', 1),\n",
       " ('refer', 1),\n",
       " (\"'jackie'\", 1),\n",
       " ('spates', 1),\n",
       " ('translates', 1),\n",
       " (\"hors-d'oeuvre\", 1),\n",
       " ('self-dramatizing', 1),\n",
       " ('filmic', 1),\n",
       " ('playboy', 1),\n",
       " ('quintessentially', 1),\n",
       " ('underlay', 1),\n",
       " ('gaiety', 1),\n",
       " ('[broomfield]', 1),\n",
       " ('sizzling', 1),\n",
       " ('sweet-natured', 1),\n",
       " (\"francisco's\", 1),\n",
       " ('fountainheads', 1),\n",
       " ('pawns', 1),\n",
       " ('bishops', 1),\n",
       " ('kings', 1),\n",
       " ('wagers', 1),\n",
       " ('dingy', 1),\n",
       " ('backrooms', 1),\n",
       " ('forests', 1),\n",
       " ('reject', 1),\n",
       " (\"python's\", 1),\n",
       " ('discontented', 1),\n",
       " (\"1983's\", 1),\n",
       " ('koyaanisqatsi', 1),\n",
       " (\"1988's\", 1),\n",
       " ('powaqqatsi', 1),\n",
       " ('naqoyqatsi', 1),\n",
       " ('nations', 1),\n",
       " ('inventively', 1),\n",
       " ('fleet', 1),\n",
       " ('extols', 1),\n",
       " ('comradeship', 1),\n",
       " ('retribution', 1),\n",
       " ('futures', 1),\n",
       " ('children--and', 1),\n",
       " ('policiales', 1),\n",
       " ('últimos', 1),\n",
       " ('tiempos', 1),\n",
       " ('modulated', 1),\n",
       " ('under-12', 1),\n",
       " ('caper-comedy', 1),\n",
       " ('laugh-filled', 1),\n",
       " ('kaputschnik', 1),\n",
       " ('renown', 1),\n",
       " ('dolgin', 1),\n",
       " ('vietnamese-born', 1),\n",
       " ('eagerly', 1),\n",
       " ('all-american', 1),\n",
       " ('infecting', 1),\n",
       " ('pasadena', 1),\n",
       " ('horror-comedy', 1),\n",
       " (\"elvira's\", 1),\n",
       " ('hooters', 1),\n",
       " ('binds', 1),\n",
       " ('grass', 1),\n",
       " ('2--quite', 1),\n",
       " ('south-of-the-border', 1),\n",
       " ('melrose', 1),\n",
       " ('erika', 1),\n",
       " ('mini-mod-madness', 1),\n",
       " ('kickass', 1),\n",
       " ('beau', 1),\n",
       " ('travil', 1),\n",
       " ('nenette', 1),\n",
       " ('boni', 1),\n",
       " ('perverted', 1),\n",
       " ('sex-soaked', 1),\n",
       " ('creator', 1),\n",
       " ('simplest', 1),\n",
       " (\"australia's\", 1),\n",
       " ('flaky', 1),\n",
       " ('bizarrely', 1),\n",
       " ('side-splittingly', 1),\n",
       " ('piper', 1),\n",
       " ('perabo', 1),\n",
       " ('sugar-sweet', 1),\n",
       " ('magnificence', 1),\n",
       " ('chorus', 1),\n",
       " ('damsels', 1),\n",
       " ('premier', 1),\n",
       " ('sarcastic', 1),\n",
       " ('shield', 1),\n",
       " ('middle-fingered', 1),\n",
       " ('outta', 1),\n",
       " ('am-radio', 1),\n",
       " ('tierney', 1),\n",
       " ('engulfing', 1),\n",
       " ('allying', 1),\n",
       " ('defeat', 1),\n",
       " ('resonates', 1),\n",
       " ('renoir', 1),\n",
       " ('non-actors', 1),\n",
       " ('no-budget', 1),\n",
       " ('subtleties', 1),\n",
       " (\"ramsay's\", 1),\n",
       " ('resent', 1),\n",
       " ('professes', 1),\n",
       " ('giddily', 1),\n",
       " ('francophiles', 1),\n",
       " ('snicker', 1),\n",
       " ('knowingly', 1),\n",
       " ('caution', 1),\n",
       " ('hedonist', 1),\n",
       " ('aborbing', 1),\n",
       " ('arguable', 1),\n",
       " ('hallucinations', 1),\n",
       " ('electrocute', 1),\n",
       " ('dismember', 1),\n",
       " ('avert', 1),\n",
       " ('mass-market', 1),\n",
       " ('child-centered', 1),\n",
       " ('toe-tapping', 1),\n",
       " ('long-range', 1),\n",
       " ('1955', 1),\n",
       " ('monkeyfun', 1),\n",
       " ('bounties', 1),\n",
       " ('artifacts', 1),\n",
       " (\"petersburg's\", 1),\n",
       " (\"[hawn's\", 1),\n",
       " ('character]is', 1),\n",
       " ('bluntly', 1),\n",
       " ('new/old', 1),\n",
       " ('exigencies', 1),\n",
       " ('adorned', 1),\n",
       " ('full-on', 1),\n",
       " ('pleasurably', 1),\n",
       " ('jacked-up', 1),\n",
       " ('philibert', 1),\n",
       " ('observes', 1),\n",
       " ('schoolhouse', 1),\n",
       " ('dainty', 1),\n",
       " ('psychopathy', 1),\n",
       " ('ecologically', 1),\n",
       " ('unconventionally', 1),\n",
       " ('half-wit', 1),\n",
       " ('venerable', 1),\n",
       " ('never-ending', 1),\n",
       " ('reheated', 1),\n",
       " ('weeping', 1),\n",
       " (\"more's\", 1),\n",
       " ('relaxing', 1),\n",
       " ('viewings', 1),\n",
       " ('lauren', 1),\n",
       " ('puzzlement', 1),\n",
       " ('symbolizes', 1),\n",
       " (\"alzheimer's\", 1),\n",
       " ('interacting', 1),\n",
       " ('eyeball-to-eyeball', 1),\n",
       " ('toe-to-toe', 1),\n",
       " (\"dragon'\", 1),\n",
       " ('open-endedness', 1),\n",
       " ('11th', 1),\n",
       " ('barbecue', 1),\n",
       " ('single-mindedly', 1),\n",
       " ('presuppose', 1),\n",
       " ('bigotry', 1),\n",
       " ('zealous', 1),\n",
       " ('nuttiness', 1),\n",
       " ('antagonists', 1),\n",
       " ('impartiality', 1),\n",
       " ('armenian-canadian', 1),\n",
       " ('broached', 1),\n",
       " ('nonagenarian', 1),\n",
       " ('boldness', 1),\n",
       " ('pentecostal', 1),\n",
       " ('dallas', 1),\n",
       " ('services', 1),\n",
       " ('warthog', 1),\n",
       " ('hyperbole', 1),\n",
       " ('bravely', 1),\n",
       " ('delve', 1),\n",
       " ('fictions', 1),\n",
       " ('peddled', 1),\n",
       " (\"'have-yourself-a-happy-little-holocaust'\", 1),\n",
       " ('jakob', 1),\n",
       " ('allegorical', 1),\n",
       " ('quench', 1),\n",
       " ('josef', 1),\n",
       " ('bierbichler', 1),\n",
       " ('monica', 1),\n",
       " ('bleibtreu', 1),\n",
       " ('helene', 1),\n",
       " ('weigel', 1),\n",
       " ('richest', 1),\n",
       " (\"[ricci's]\", 1),\n",
       " ('girl-woman', 1),\n",
       " ('thwart', 1),\n",
       " ('crummles', 1),\n",
       " ('[howard]', 1),\n",
       " ('crossing', 1),\n",
       " ('gut-bustingly', 1),\n",
       " ('thinnest', 1),\n",
       " ('sleepy', 1),\n",
       " ('declares', 1),\n",
       " ('yang', 1),\n",
       " ('expressed', 1),\n",
       " ('82', 1),\n",
       " ('bend', 1),\n",
       " ('glories', 1),\n",
       " ('connecting', 1),\n",
       " ('historians', 1),\n",
       " (\"'70's\", 1),\n",
       " ('viciously', 1),\n",
       " ('griping', 1),\n",
       " ('garry', 1),\n",
       " ('shandling', 1),\n",
       " ('[sade]', 1),\n",
       " ('deceitful', 1),\n",
       " ('idealistically', 1),\n",
       " ('selfless', 1),\n",
       " ('coldly', 1),\n",
       " ('self-interested', 1),\n",
       " ('unselfconscious', 1),\n",
       " ('munch', 1),\n",
       " ('invariably', 1),\n",
       " ('cockamamie', 1),\n",
       " ('precipitously', 1),\n",
       " ('catastrophe', 1),\n",
       " ('nerve-wracking', 1),\n",
       " ('screamingly', 1),\n",
       " ('[binoche', 1),\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 倒序查看词频\n",
    "sorted(c.most_common(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 初始化两个token：pad和unk\n",
    "vocab = [\"<pad>\", \"<unk>\"]\n",
    "\n",
    "# 去除出现频次为1次的单词\n",
    "for w, f in c.most_common():\n",
    "    if f > 1:\n",
    "        vocab.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total size of our vocabulary is: 10384\n"
     ]
    }
   ],
   "source": [
    "print(\"The total size of our vocabulary is: {}\".format(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 单词到编码的映射，例如machine -> 10283\n",
    "word_to_token = {word: token for token, word in enumerate(vocab)}\n",
    "# 编码到单词的映射，例如10283 -> machine\n",
    "token_to_word = {token: word for word, token in word_to_token.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 转换文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_text_to_token(sentence, word_to_token_map=word_to_token, limit_size=SENTENCE_LIMIT_SIZE):\n",
    "    \"\"\"\n",
    "    根据单词-编码映射表将单个句子转化为token\n",
    "    \n",
    "    @param sentence: 句子，str类型\n",
    "    @param word_to_token_map: 单词到编码的映射\n",
    "    @param limit_size: 句子最大长度。超过该长度的句子进行截断，不足的句子进行pad补全\n",
    "    \n",
    "    return: 句子转换为token后的列表\n",
    "    \"\"\"\n",
    "    # 获取unknown单词和pad的token\n",
    "    unk_id = word_to_token_map[\"<unk>\"]\n",
    "    pad_id = word_to_token_map[\"<pad>\"]\n",
    "    \n",
    "    # 对句子进行token转换，对于未在词典中出现过的词用unk的token填充\n",
    "    tokens = [word_to_token_map.get(word, unk_id) for word in sentence.lower().split()]\n",
    "    \n",
    "    # Pad\n",
    "    if len(tokens) < limit_size:\n",
    "        tokens.extend([0] * (limit_size - len(tokens)))\n",
    "    # Trunc\n",
    "    else:\n",
    "        tokens = tokens[:limit_size]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5331/5331 [00:00<00:00, 108848.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# 对pos文本处理\n",
    "pos_tokens = []\n",
    "\n",
    "for sentence in tqdm.tqdm(pos_sentences):\n",
    "    tokens = convert_text_to_token(sentence)\n",
    "    pos_tokens.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5331/5331 [00:00<00:00, 103560.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# 对neg文本处理\n",
    "neg_tokens = []\n",
    "\n",
    "for sentence in tqdm.tqdm(neg_sentences):\n",
    "    tokens = convert_text_to_token(sentence)\n",
    "    neg_tokens.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 转化为numpy格式，方便处理\n",
    "pos_tokens = np.array(pos_tokens)\n",
    "neg_tokens = np.array(neg_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 合并所有语料\n",
    "total_tokens = np.concatenate((pos_tokens, neg_tokens), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of all tokens in our corpus: (10662, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of all tokens in our corpus: ({}, {})\".format(*total_tokens.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 转化为numpy格式，方便处理\n",
    "pos_targets = np.ones((pos_tokens.shape[0]))\n",
    "neg_targets = np.zeros((neg_tokens.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 合并所有target\n",
    "total_targets = np.concatenate((pos_targets, neg_targets), axis=0).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of all targets in our corpus: (10662, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of all targets in our corpus: ({}, {})\".format(*total_targets.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造词向量\n",
    "\n",
    "我们使用glove预训练好的词向量来做embedding:\n",
    "\n",
    "- 如果当前词没有对应词向量，则用随机数产生的向量替代\n",
    "- 如果当前词为< PAD >，则用0向量代替"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载glove预训练词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 加载预训练好的glove词向量\n",
    "with open(\"data/glove.6B.300d.txt\", 'r') as f:\n",
    "    words = set()\n",
    "    word_to_vec = {}\n",
    "    for line in f:\n",
    "        line = line.strip().split()\n",
    "        # 当前单词\n",
    "        curr_word = line[0]\n",
    "        words.add(curr_word)\n",
    "        # 当前词向量\n",
    "        word_to_vec[curr_word] = np.array(line[1:], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words which have pretrained-vectors in vocab is: 9801\n",
      "\n",
      "The number of words which do not have pretrained-vectors in vocab is : 583\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of words which have pretrained-vectors in vocab is: {}\".format(len(set(vocab)&set(words))))\n",
    "print()\n",
    "print(\"The number of words which do not have pretrained-vectors in vocab is : {}\".format(len(set(vocab))-\n",
    "                                                                                         len(set(vocab)&set(words))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造词向量矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocab)  # 10384\n",
    "EMBEDDING_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10384/10384 [00:00<00:00, 61619.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# 初始化词向量矩阵（这里命名为static是因为这个词向量矩阵用预训练好的填充，无需重新训练）\n",
    "static_embeddings = np.zeros([VOCAB_SIZE, EMBEDDING_SIZE])\n",
    "\n",
    "for word, token in tqdm.tqdm(word_to_token.items()):\n",
    "    # 用glove词向量填充，如果没有对应的词向量，则用随机数填充\n",
    "    word_vector = word_to_vec.get(word, 0.2 * np.random.random(EMBEDDING_SIZE) - 0.1)\n",
    "    static_embeddings[token, :] = word_vector\n",
    "\n",
    "# 重置PAD为0向量\n",
    "pad_id = word_to_token[\"<pad>\"]\n",
    "static_embeddings[pad_id, :] = np.zeros(EMBEDDING_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "static_embeddings = static_embeddings.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 辅助函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分割train和test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_train_test(x, y, train_ratio=0.8, shuffle=True):\n",
    "    \"\"\"\n",
    "    分割train和test\n",
    "    \n",
    "    @param x: 输入特征\n",
    "    @param y: 目标\n",
    "    @param train_ratio: 训练样本比例\n",
    "    @param shuffle: 是否shuffle\n",
    "    \"\"\"\n",
    "    assert x.shape[0] == y.shape[0],  print(\"error shape!\")\n",
    "    \n",
    "    if shuffle:\n",
    "        # shuffle\n",
    "        shuffled_index = np.random.permutation(range(x.shape[0]))\n",
    "        x = x[shuffled_index]\n",
    "        y = y[shuffled_index]\n",
    "    \n",
    "    # 分离train和test\n",
    "    train_size = int(x.shape[0] * train_ratio)\n",
    "    x_train = x[:train_size]\n",
    "    x_test = x[train_size:]\n",
    "    y_train = y[:train_size]\n",
    "    y_test = y[train_size:]\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 划分train和test\n",
    "x_train, x_test, y_train, y_test = split_train_test(total_tokens, total_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_batch函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(x, y, batch_size=BATCH_SIZE, shuffle=True):\n",
    "    assert x.shape[0] == y.shape[0], print(\"error shape!\")\n",
    "    # shuffle\n",
    "    if shuffle:\n",
    "        shuffled_index = np.random.permutation(range(x.shape[0]))\n",
    "\n",
    "        x = x[shuffled_index]\n",
    "        y = y[shuffled_index]\n",
    "    \n",
    "    # 统计共几个完整的batch\n",
    "    n_batches = int(x.shape[0] / batch_size)\n",
    "    \n",
    "    for i in range(n_batches - 1):\n",
    "        x_batch = x[i*batch_size: (i+1)*batch_size]\n",
    "        y_batch = y[i*batch_size: (i+1)*batch_size]\n",
    "    \n",
    "        yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型图\n",
    "\n",
    "<img src=\"images/dnn.png\" style=\"width:500;height:500px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 清空图\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义神经网络超参数\n",
    "HIDDEN_SIZE = 512\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHES = 50\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    # 输入及输出tensor\n",
    "    with tf.name_scope(\"placeholders\"):\n",
    "        inputs = tf.placeholder(dtype=tf.int32, shape=(None, SENTENCE_LIMIT_SIZE), name=\"inputs\")\n",
    "        targets = tf.placeholder(dtype=tf.float32, shape=(None, 1), name=\"targets\")\n",
    "    \n",
    "    # embeddings\n",
    "    with tf.name_scope(\"embeddings\"):\n",
    "        # 用pre-trained词向量来作为embedding层\n",
    "        embedding_matrix = tf.Variable(initial_value=static_embeddings, trainable=False, name=\"embedding_matrix\")\n",
    "        embed = tf.nn.embedding_lookup(embedding_matrix, inputs, name=\"embed\")\n",
    "        # 相加词向量得到句子向量\n",
    "        sum_embed = tf.reduce_sum(embed, axis=1, name=\"sum_embed\")\n",
    "        \n",
    "    # model\n",
    "    with tf.name_scope(\"model\"):\n",
    "        # 隐层权重\n",
    "        W1 = tf.Variable(tf.random_normal(shape=(EMBEDDING_SIZE, HIDDEN_SIZE), stddev=0.1), name=\"W1\")\n",
    "        b1 = tf.Variable(tf.zeros(shape=(HIDDEN_SIZE), name=\"b1\"))\n",
    "        \n",
    "        # 输出层权重\n",
    "        W2 = tf.Variable(tf.random_normal(shape=(HIDDEN_SIZE, 1), stddev=0.1), name=\"W2\")\n",
    "        b2 = tf.Variable(tf.zeros(shape=(1), name=\"b2\"))\n",
    "        \n",
    "        # 结果\n",
    "        z1 = tf.add(tf.matmul(sum_embed, W1), b1)\n",
    "        a1 = tf.nn.relu(z1)\n",
    "        \n",
    "        logits = tf.add(tf.matmul(a1, W2), b2)\n",
    "        outputs = tf.nn.sigmoid(logits, name=\"outputs\")\n",
    "    \n",
    "    # loss\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=targets, logits=logits))\n",
    "    \n",
    "    # optimizer\n",
    "    with tf.name_scope(\"optimizer\"):\n",
    "        optimizer = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)\n",
    "        \n",
    "    # evaluation\n",
    "    with tf.name_scope(\"evaluation\"):\n",
    "        correct_preds = tf.equal(tf.cast(tf.greater(outputs, 0.5), tf.float32), targets)\n",
    "        accuracy = tf.reduce_sum(tf.reduce_sum(tf.cast(correct_preds, tf.float32), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 存储准确率\n",
    "dnn_train_accuracy = []\n",
    "dnn_test_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 0.9776, Train accuracy: 0.7222, Test accuracy: 0.7089\n",
      "Epoch: 2, Train loss: 0.6184, Train accuracy: 0.7553, Test accuracy: 0.7126\n",
      "Epoch: 3, Train loss: 0.5681, Train accuracy: 0.7673, Test accuracy: 0.7164\n",
      "Epoch: 4, Train loss: 0.4983, Train accuracy: 0.7909, Test accuracy: 0.7295\n",
      "Epoch: 5, Train loss: 0.4666, Train accuracy: 0.7931, Test accuracy: 0.6981\n",
      "Epoch: 6, Train loss: 0.4239, Train accuracy: 0.8216, Test accuracy: 0.7140\n",
      "Epoch: 7, Train loss: 0.4829, Train accuracy: 0.7902, Test accuracy: 0.6915\n",
      "Epoch: 8, Train loss: 0.4098, Train accuracy: 0.8443, Test accuracy: 0.7182\n",
      "Epoch: 9, Train loss: 0.3423, Train accuracy: 0.8778, Test accuracy: 0.7215\n",
      "Epoch: 10, Train loss: 0.3247, Train accuracy: 0.8606, Test accuracy: 0.7028\n",
      "Epoch: 11, Train loss: 0.2852, Train accuracy: 0.9185, Test accuracy: 0.7173\n",
      "Epoch: 12, Train loss: 0.2792, Train accuracy: 0.9264, Test accuracy: 0.7276\n",
      "Epoch: 13, Train loss: 0.2285, Train accuracy: 0.9323, Test accuracy: 0.7243\n",
      "Epoch: 14, Train loss: 0.2016, Train accuracy: 0.9524, Test accuracy: 0.7281\n",
      "Epoch: 15, Train loss: 0.1950, Train accuracy: 0.9490, Test accuracy: 0.7267\n",
      "Epoch: 16, Train loss: 0.1861, Train accuracy: 0.9601, Test accuracy: 0.7314\n",
      "Epoch: 17, Train loss: 0.1450, Train accuracy: 0.9771, Test accuracy: 0.7323\n",
      "Epoch: 18, Train loss: 0.1545, Train accuracy: 0.9342, Test accuracy: 0.7004\n",
      "Epoch: 19, Train loss: 0.1244, Train accuracy: 0.9755, Test accuracy: 0.7346\n",
      "Epoch: 20, Train loss: 0.0990, Train accuracy: 0.9864, Test accuracy: 0.7379\n",
      "Epoch: 21, Train loss: 0.0847, Train accuracy: 0.9947, Test accuracy: 0.7365\n",
      "Epoch: 22, Train loss: 0.0725, Train accuracy: 0.9950, Test accuracy: 0.7370\n",
      "Epoch: 23, Train loss: 0.0804, Train accuracy: 0.9906, Test accuracy: 0.7206\n",
      "Epoch: 24, Train loss: 0.0719, Train accuracy: 0.9739, Test accuracy: 0.7018\n",
      "Epoch: 25, Train loss: 0.0570, Train accuracy: 0.9987, Test accuracy: 0.7398\n",
      "Epoch: 26, Train loss: 0.0440, Train accuracy: 0.9992, Test accuracy: 0.7351\n",
      "Epoch: 27, Train loss: 0.0359, Train accuracy: 0.9995, Test accuracy: 0.7356\n",
      "Epoch: 28, Train loss: 0.0361, Train accuracy: 0.9994, Test accuracy: 0.7398\n",
      "Epoch: 29, Train loss: 0.0288, Train accuracy: 0.9989, Test accuracy: 0.7328\n",
      "Epoch: 30, Train loss: 0.0269, Train accuracy: 1.0000, Test accuracy: 0.7375\n",
      "Epoch: 31, Train loss: 0.0223, Train accuracy: 0.9998, Test accuracy: 0.7361\n",
      "Epoch: 32, Train loss: 0.0209, Train accuracy: 1.0000, Test accuracy: 0.7332\n",
      "Epoch: 33, Train loss: 0.0182, Train accuracy: 1.0000, Test accuracy: 0.7318\n",
      "Epoch: 34, Train loss: 0.0159, Train accuracy: 1.0000, Test accuracy: 0.7342\n",
      "Epoch: 35, Train loss: 0.0137, Train accuracy: 1.0000, Test accuracy: 0.7290\n",
      "Epoch: 36, Train loss: 0.0128, Train accuracy: 1.0000, Test accuracy: 0.7384\n",
      "Epoch: 37, Train loss: 0.0126, Train accuracy: 1.0000, Test accuracy: 0.7384\n",
      "Epoch: 38, Train loss: 0.0104, Train accuracy: 1.0000, Test accuracy: 0.7337\n",
      "Epoch: 39, Train loss: 0.0095, Train accuracy: 1.0000, Test accuracy: 0.7370\n",
      "Epoch: 40, Train loss: 0.0089, Train accuracy: 1.0000, Test accuracy: 0.7323\n",
      "Epoch: 41, Train loss: 0.0082, Train accuracy: 1.0000, Test accuracy: 0.7398\n",
      "Epoch: 42, Train loss: 0.0076, Train accuracy: 1.0000, Test accuracy: 0.7365\n",
      "Epoch: 43, Train loss: 0.0069, Train accuracy: 1.0000, Test accuracy: 0.7346\n",
      "Epoch: 44, Train loss: 0.0064, Train accuracy: 1.0000, Test accuracy: 0.7379\n",
      "Epoch: 45, Train loss: 0.0066, Train accuracy: 1.0000, Test accuracy: 0.7332\n",
      "Epoch: 46, Train loss: 0.0057, Train accuracy: 1.0000, Test accuracy: 0.7412\n",
      "Epoch: 47, Train loss: 0.0053, Train accuracy: 1.0000, Test accuracy: 0.7379\n",
      "Epoch: 48, Train loss: 0.0048, Train accuracy: 1.0000, Test accuracy: 0.7361\n",
      "Epoch: 49, Train loss: 0.0045, Train accuracy: 1.0000, Test accuracy: 0.7370\n",
      "Epoch: 50, Train loss: 0.0042, Train accuracy: 1.0000, Test accuracy: 0.7346\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    writer = tf.summary.FileWriter(\"./graphs/dnn\", tf.get_default_graph())\n",
    "    \n",
    "    n_batches = int(x_train.shape[0] / BATCH_SIZE)\n",
    "    \n",
    "    for epoch in range(EPOCHES):\n",
    "        total_loss = 0\n",
    "        \n",
    "        for x_batch, y_batch in get_batch(x_train, y_train):\n",
    "            _, batch_loss = sess.run([optimizer, loss],\n",
    "                                     feed_dict={inputs: x_batch, targets: y_batch})\n",
    "            \n",
    "            total_loss += batch_loss\n",
    "        \n",
    "        # 在train上准确率\n",
    "        train_corrects = sess.run(accuracy, feed_dict={inputs: x_train, targets: y_train})\n",
    "        train_acc = train_corrects / x_train.shape[0]\n",
    "        dnn_train_accuracy.append(train_acc)\n",
    "        \n",
    "        # 在test上准确率\n",
    "        test_corrects = sess.run(accuracy, feed_dict={inputs: x_test, targets: y_test})\n",
    "        test_acc = test_corrects / x_test.shape[0]\n",
    "        dnn_test_accuracy.append(test_acc)\n",
    "        \n",
    "        print(\"Epoch: {}, Train loss: {:.4f}, Train accuracy: {:.4f}, Test accuracy: {:.4f}\".format(epoch + 1, \n",
    "                                                                                                    total_loss/n_batches,\n",
    "                                                                                                    train_acc,\n",
    "                                                                                                    test_acc))\n",
    "    # 存储模型\n",
    "    saver.save(sess, \"./checkpoints/dnn\")\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18228b3128>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1822724eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dnn_train_accuracy)\n",
    "plt.plot(dnn_test_accuracy)\n",
    "plt.ylim(ymin=0.5, ymax=1.01)\n",
    "plt.title(\"The accuracy of DNN model\")\n",
    "plt.legend([\"train\", \"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/dnn\n",
      "The DNN model accuracy on test set: 73.46%\n"
     ]
    }
   ],
   "source": [
    "# 在test上的准确率\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"checkpoints/dnn\")\n",
    "    \n",
    "    total_correct = 0\n",
    "    acc = sess.run(accuracy,\n",
    "                    feed_dict={inputs: x_test, \n",
    "                                targets: y_test})\n",
    "    total_correct += acc\n",
    "    print(\"The DNN model accuracy on test set: {:.2f}%\".format(100* total_correct / x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在命令行执行tensorboard --logdir=\"./graphs/dnn\" --port 6006可以看到模型的tensorboard\n",
    "\n",
    "<img src=\"images/dnn-tensorboard.png\" style=\"width:500;height:500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 清空图\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义网络超参数\n",
    "HIDDEN_SIZE = 512\n",
    "LEARNING_RATE = 0.001\n",
    "KEEP_PROB = 0.5\n",
    "EPOCHES = 50\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"rnn\"):\n",
    "    # placeholders\n",
    "    with tf.name_scope(\"placeholders\"):\n",
    "        inputs = tf.placeholder(dtype=tf.int32, shape=(None, 20), name=\"inputs\")\n",
    "        targets = tf.placeholder(dtype=tf.float32, shape=(None, 1), name=\"targets\")\n",
    "    \n",
    "    # embeddings\n",
    "    with tf.name_scope(\"embeddings\"):\n",
    "        embedding_matrix = tf.Variable(initial_value=static_embeddings, trainable=False, name=\"embedding_matrix\")\n",
    "        embed = tf.nn.embedding_lookup(embedding_matrix, inputs, name=\"embed\")\n",
    "    \n",
    "    # model\n",
    "    with tf.name_scope(\"model\"):\n",
    "        # 构造lstm单元\n",
    "        lstm = tf.contrib.rnn.LSTMCell(HIDDEN_SIZE, initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=123))\n",
    "        # 添加dropout\n",
    "        drop_lstm = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=KEEP_PROB)\n",
    "        _, lstm_state = tf.nn.dynamic_rnn(drop_lstm, embed, dtype=tf.float32)\n",
    "        \n",
    "        # 输出层权重\n",
    "        W = tf.Variable(tf.truncated_normal((HIDDEN_SIZE, 1), mean=0.0, stddev=0.1), name=\"W\")\n",
    "        b = tf.Variable(tf.zeros(1), name=\"b\")\n",
    "        \n",
    "        logits = tf.add(tf.matmul(lstm_state.h, W), b)\n",
    "        outputs = tf.nn.sigmoid(logits, name=\"outputs\")\n",
    "        \n",
    "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=targets, logits=logits))\n",
    "    \n",
    "    # optimizer\n",
    "    with tf.name_scope(\"optimizer\"):\n",
    "        optimizer = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)\n",
    "    \n",
    "    # evaluation\n",
    "    with tf.name_scope(\"evaluation\"):\n",
    "        correct_preds = tf.equal(tf.cast(tf.greater(outputs, 0.5), tf.float32), targets)\n",
    "        accuracy = tf.reduce_sum(tf.reduce_sum(tf.cast(correct_preds, tf.float32), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 存储准确率\n",
    "rnn_train_accuracy = []\n",
    "rnn_test_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1, Train loss: 1.2306, Train accuracy: 0.7559, Test accuracy: 0.7318\n",
      "Training epoch: 2, Train loss: 0.9780, Train accuracy: 0.7838, Test accuracy: 0.7309\n",
      "Training epoch: 3, Train loss: 0.9003, Train accuracy: 0.8061, Test accuracy: 0.7314\n",
      "Training epoch: 4, Train loss: 0.8172, Train accuracy: 0.8483, Test accuracy: 0.7417\n",
      "Training epoch: 5, Train loss: 0.7124, Train accuracy: 0.8801, Test accuracy: 0.7407\n",
      "Training epoch: 6, Train loss: 0.5750, Train accuracy: 0.8792, Test accuracy: 0.7159\n",
      "Training epoch: 7, Train loss: 0.5087, Train accuracy: 0.9417, Test accuracy: 0.7290\n",
      "Training epoch: 8, Train loss: 0.3743, Train accuracy: 0.9546, Test accuracy: 0.7267\n",
      "Training epoch: 9, Train loss: 0.2559, Train accuracy: 0.9730, Test accuracy: 0.7346\n",
      "Training epoch: 10, Train loss: 0.1711, Train accuracy: 0.9757, Test accuracy: 0.7239\n",
      "Training epoch: 11, Train loss: 0.1832, Train accuracy: 0.9811, Test accuracy: 0.7243\n",
      "Training epoch: 12, Train loss: 0.1170, Train accuracy: 0.9852, Test accuracy: 0.7426\n",
      "Training epoch: 13, Train loss: 0.1123, Train accuracy: 0.9842, Test accuracy: 0.7135\n",
      "Training epoch: 14, Train loss: 0.0771, Train accuracy: 0.9906, Test accuracy: 0.7328\n",
      "Training epoch: 15, Train loss: 0.0751, Train accuracy: 0.9960, Test accuracy: 0.7337\n",
      "Training epoch: 16, Train loss: 0.0340, Train accuracy: 0.9982, Test accuracy: 0.7257\n",
      "Training epoch: 17, Train loss: 0.0345, Train accuracy: 0.9964, Test accuracy: 0.7135\n",
      "Training epoch: 18, Train loss: 0.0471, Train accuracy: 0.9964, Test accuracy: 0.7314\n",
      "Training epoch: 19, Train loss: 0.0430, Train accuracy: 0.9966, Test accuracy: 0.7337\n",
      "Training epoch: 20, Train loss: 0.0559, Train accuracy: 0.9970, Test accuracy: 0.7271\n",
      "Training epoch: 21, Train loss: 0.0476, Train accuracy: 0.9921, Test accuracy: 0.7239\n",
      "Training epoch: 22, Train loss: 0.0535, Train accuracy: 0.9937, Test accuracy: 0.7356\n",
      "Training epoch: 23, Train loss: 0.0551, Train accuracy: 0.9965, Test accuracy: 0.7271\n",
      "Training epoch: 24, Train loss: 0.0316, Train accuracy: 0.9950, Test accuracy: 0.7281\n",
      "Training epoch: 25, Train loss: 0.0343, Train accuracy: 0.9984, Test accuracy: 0.7389\n",
      "Training epoch: 26, Train loss: 0.0303, Train accuracy: 0.9972, Test accuracy: 0.7337\n",
      "Training epoch: 27, Train loss: 0.0344, Train accuracy: 0.9978, Test accuracy: 0.7318\n",
      "Training epoch: 28, Train loss: 0.0239, Train accuracy: 0.9992, Test accuracy: 0.7398\n",
      "Training epoch: 29, Train loss: 0.0132, Train accuracy: 0.9992, Test accuracy: 0.7276\n",
      "Training epoch: 30, Train loss: 0.0097, Train accuracy: 0.9995, Test accuracy: 0.7379\n",
      "Training epoch: 31, Train loss: 0.0216, Train accuracy: 0.9948, Test accuracy: 0.7393\n",
      "Training epoch: 32, Train loss: 0.0242, Train accuracy: 0.9968, Test accuracy: 0.7300\n",
      "Training epoch: 33, Train loss: 0.0374, Train accuracy: 0.9960, Test accuracy: 0.7332\n",
      "Training epoch: 34, Train loss: 0.0301, Train accuracy: 0.9968, Test accuracy: 0.7379\n",
      "Training epoch: 35, Train loss: 0.0320, Train accuracy: 0.9984, Test accuracy: 0.7318\n",
      "Training epoch: 36, Train loss: 0.0186, Train accuracy: 0.9994, Test accuracy: 0.7450\n",
      "Training epoch: 37, Train loss: 0.0033, Train accuracy: 1.0000, Test accuracy: 0.7356\n",
      "Training epoch: 38, Train loss: 0.0014, Train accuracy: 1.0000, Test accuracy: 0.7389\n",
      "Training epoch: 39, Train loss: 0.0004, Train accuracy: 1.0000, Test accuracy: 0.7361\n",
      "Training epoch: 40, Train loss: 0.0002, Train accuracy: 1.0000, Test accuracy: 0.7370\n",
      "Training epoch: 41, Train loss: 0.0002, Train accuracy: 1.0000, Test accuracy: 0.7346\n",
      "Training epoch: 42, Train loss: 0.0001, Train accuracy: 1.0000, Test accuracy: 0.7346\n",
      "Training epoch: 43, Train loss: 0.0001, Train accuracy: 1.0000, Test accuracy: 0.7351\n",
      "Training epoch: 44, Train loss: 0.0001, Train accuracy: 1.0000, Test accuracy: 0.7346\n",
      "Training epoch: 45, Train loss: 0.0001, Train accuracy: 1.0000, Test accuracy: 0.7346\n",
      "Training epoch: 46, Train loss: 0.0001, Train accuracy: 1.0000, Test accuracy: 0.7351\n",
      "Training epoch: 47, Train loss: 0.0001, Train accuracy: 1.0000, Test accuracy: 0.7351\n",
      "Training epoch: 48, Train loss: 0.0001, Train accuracy: 1.0000, Test accuracy: 0.7346\n",
      "Training epoch: 49, Train loss: 0.0001, Train accuracy: 1.0000, Test accuracy: 0.7342\n",
      "Training epoch: 50, Train loss: 0.0001, Train accuracy: 1.0000, Test accuracy: 0.7337\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    writer = tf.summary.FileWriter(\"./graphs/rnn\", tf.get_default_graph())\n",
    "    n_batches = int(x_train.shape[0] / BATCH_SIZE)\n",
    "    \n",
    "    for epoch in range(EPOCHES):\n",
    "        total_loss = 0\n",
    "        for x_batch, y_batch in get_batch(x_train, y_train):\n",
    "            _, l = sess.run([optimizer, loss],\n",
    "                            feed_dict={inputs: x_batch, \n",
    "                                       targets: y_batch})\n",
    "            total_loss += l\n",
    "        \n",
    "        train_corrects = sess.run(accuracy, feed_dict={inputs: x_train, targets: y_train})\n",
    "        train_acc = train_corrects / x_train.shape[0]\n",
    "        rnn_train_accuracy.append(train_acc)\n",
    "\n",
    "        test_corrects = sess.run(accuracy, feed_dict={inputs: x_test, targets: y_test})\n",
    "        test_acc = test_corrects / x_test.shape[0]\n",
    "        rnn_test_accuracy.append(test_acc)\n",
    "\n",
    "        \n",
    "        print(\"Training epoch: {}, Train loss: {:.4f}, Train accuracy: {:.4f}, Test accuracy: {:.4f}\".format(epoch + 1, \n",
    "                                                                                                             total_loss / n_batches,\n",
    "                                                                                                             train_acc,\n",
    "                                                                                                             test_acc))\n",
    "    \n",
    "    saver.save(sess, \"checkpoints/rnn\")\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1820f5a6d8>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1828d18fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rnn_train_accuracy)\n",
    "plt.plot(rnn_test_accuracy)\n",
    "plt.ylim(ymin=0.5, ymax=1.01)\n",
    "plt.title(\"The accuracy of LSTM model\")\n",
    "plt.legend([\"train\", \"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/rnn\n",
      "The LSTM model accuracy on test set: 73.37%\n"
     ]
    }
   ],
   "source": [
    "# 在test上的准确率\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"checkpoints/rnn\")\n",
    "    \n",
    "    total_correct = sess.run(accuracy,\n",
    "                             feed_dict={inputs: x_test, targets: y_test})\n",
    "\n",
    "    print(\"The LSTM model accuracy on test set: {:.2f}%\".format(100* total_correct / x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在命令行执行tensorboard --logdir=\"./graphs/rnn\" --port 6006可以看到模型的tensorboard\n",
    "\n",
    "<img src=\"images/lstm-tensorboard.png\" style=\"width:500;height:500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 清空图\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 我在这里定义了5种filter，每种100个\n",
    "filters_size = [2, 3, 4, 5, 6]\n",
    "num_filters = 100\n",
    "# 超参数\n",
    "BATCH_SIZE = 256\n",
    "EPOCHES = 50\n",
    "LEARNING_RATE = 0.001\n",
    "L2_LAMBDA = 10\n",
    "KEEP_PROB = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"cnn\"):\n",
    "    with tf.name_scope(\"placeholders\"):\n",
    "        inputs = tf.placeholder(dtype=tf.int32, shape=(None, 20), name=\"inputs\")\n",
    "        targets = tf.placeholder(dtype=tf.float32, shape=(None, 1), name=\"targets\")\n",
    "    \n",
    "    # embeddings\n",
    "    with tf.name_scope(\"embeddings\"):\n",
    "        embedding_matrix = tf.Variable(initial_value=static_embeddings, trainable=False, name=\"embedding_matrix\")\n",
    "        embed = tf.nn.embedding_lookup(embedding_matrix, inputs, name=\"embed\")\n",
    "        # 添加channel维度\n",
    "        embed_expanded = tf.expand_dims(embed, -1, name=\"embed_expand\")\n",
    "    \n",
    "    # 用来存储max-pooling的结果\n",
    "    pooled_outputs = []\n",
    "\n",
    "    # 迭代多个filter\n",
    "    for i, filter_size in enumerate(filters_size):\n",
    "        with tf.name_scope(\"conv_maxpool_%s\" % filter_size):\n",
    "            filter_shape = [filter_size, EMBEDDING_SIZE, 1, num_filters]\n",
    "            W = tf.Variable(tf.truncated_normal(filter_shape, mean=0.0, stddev=0.1), name=\"W\")\n",
    "            b = tf.Variable(tf.zeros(num_filters), name=\"b\")\n",
    "\n",
    "            conv = tf.nn.conv2d(input=embed_expanded, \n",
    "                                 filter=W, \n",
    "                                 strides=[1, 1, 1, 1], \n",
    "                                 padding=\"VALID\",\n",
    "                                 name=\"conv\")\n",
    "\n",
    "            # 激活\n",
    "            a = tf.nn.relu(tf.nn.bias_add(conv, b), name=\"activations\")\n",
    "            # 池化\n",
    "            max_pooling = tf.nn.max_pool(value=a, \n",
    "                                    ksize=[1, SENTENCE_LIMIT_SIZE - filter_size + 1, 1, 1],\n",
    "                                    strides=[1, 1, 1, 1],\n",
    "                                    padding=\"VALID\",\n",
    "                                    name=\"max_pooling\")\n",
    "            pooled_outputs.append(max_pooling)\n",
    "    \n",
    "    # 统计所有的filter\n",
    "    total_filters = num_filters * len(filters_size)\n",
    "    total_pool = tf.concat(pooled_outputs, 3)\n",
    "    flattend_pool = tf.reshape(total_pool, (-1, total_filters))\n",
    "    \n",
    "    # dropout\n",
    "    with tf.name_scope(\"dropout\"):\n",
    "        dropout = tf.nn.dropout(flattend_pool, KEEP_PROB)\n",
    "    \n",
    "    # output\n",
    "    with tf.name_scope(\"output\"):\n",
    "        W = tf.get_variable(\"W\", shape=(total_filters, 1), initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b = tf.Variable(tf.zeros(1), name=\"b\")\n",
    "        \n",
    "        logits = tf.add(tf.matmul(dropout, W), b)\n",
    "        predictions = tf.nn.sigmoid(logits, name=\"predictions\")\n",
    "    \n",
    "    # loss\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=targets, logits=logits))\n",
    "        loss = loss + L2_LAMBDA * tf.nn.l2_loss(W)\n",
    "        optimizer = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)\n",
    "    \n",
    "    # evaluation\n",
    "    with tf.name_scope(\"evaluation\"):\n",
    "        correct_preds = tf.equal(tf.cast(tf.greater(predictions, 0.5), tf.float32), targets)\n",
    "        accuracy = tf.reduce_sum(tf.reduce_sum(tf.cast(correct_preds, tf.float32), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 存储准确率\n",
    "cnn_train_accuracy = []\n",
    "cnn_test_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1, Training loss: 9.8113, Train accuracy: 0.7357, Test accuracy: 0.6714\n",
      "Training epoch: 2, Training loss: 2.0410, Train accuracy: 0.7422, Test accuracy: 0.6934\n",
      "Training epoch: 3, Training loss: 1.3115, Train accuracy: 0.7473, Test accuracy: 0.7145\n",
      "Training epoch: 4, Training loss: 1.2251, Train accuracy: 0.7541, Test accuracy: 0.7267\n",
      "Training epoch: 5, Training loss: 1.1713, Train accuracy: 0.7769, Test accuracy: 0.7365\n",
      "Training epoch: 6, Training loss: 1.1336, Train accuracy: 0.7769, Test accuracy: 0.7304\n",
      "Training epoch: 7, Training loss: 1.0963, Train accuracy: 0.7822, Test accuracy: 0.7375\n",
      "Training epoch: 8, Training loss: 1.0792, Train accuracy: 0.7958, Test accuracy: 0.7346\n",
      "Training epoch: 9, Training loss: 1.0572, Train accuracy: 0.7959, Test accuracy: 0.7393\n",
      "Training epoch: 10, Training loss: 1.0346, Train accuracy: 0.8023, Test accuracy: 0.7412\n",
      "Training epoch: 11, Training loss: 1.0174, Train accuracy: 0.8105, Test accuracy: 0.7403\n",
      "Training epoch: 12, Training loss: 1.0075, Train accuracy: 0.8152, Test accuracy: 0.7454\n",
      "Training epoch: 13, Training loss: 0.9843, Train accuracy: 0.8207, Test accuracy: 0.7450\n",
      "Training epoch: 14, Training loss: 0.9795, Train accuracy: 0.8244, Test accuracy: 0.7403\n",
      "Training epoch: 15, Training loss: 0.9687, Train accuracy: 0.8299, Test accuracy: 0.7436\n",
      "Training epoch: 16, Training loss: 0.9538, Train accuracy: 0.8268, Test accuracy: 0.7450\n",
      "Training epoch: 17, Training loss: 0.9350, Train accuracy: 0.8336, Test accuracy: 0.7426\n",
      "Training epoch: 18, Training loss: 0.9231, Train accuracy: 0.8478, Test accuracy: 0.7539\n",
      "Training epoch: 19, Training loss: 0.9122, Train accuracy: 0.8378, Test accuracy: 0.7506\n",
      "Training epoch: 20, Training loss: 0.8911, Train accuracy: 0.8571, Test accuracy: 0.7501\n",
      "Training epoch: 21, Training loss: 0.8844, Train accuracy: 0.8560, Test accuracy: 0.7431\n",
      "Training epoch: 22, Training loss: 0.8751, Train accuracy: 0.8615, Test accuracy: 0.7473\n",
      "Training epoch: 23, Training loss: 0.8638, Train accuracy: 0.8747, Test accuracy: 0.7506\n",
      "Training epoch: 24, Training loss: 0.8531, Train accuracy: 0.8763, Test accuracy: 0.7496\n",
      "Training epoch: 25, Training loss: 0.8400, Train accuracy: 0.8812, Test accuracy: 0.7557\n",
      "Training epoch: 26, Training loss: 0.8325, Train accuracy: 0.8661, Test accuracy: 0.7459\n",
      "Training epoch: 27, Training loss: 0.8292, Train accuracy: 0.8904, Test accuracy: 0.7586\n",
      "Training epoch: 28, Training loss: 0.8086, Train accuracy: 0.8934, Test accuracy: 0.7557\n",
      "Training epoch: 29, Training loss: 0.8017, Train accuracy: 0.8940, Test accuracy: 0.7529\n",
      "Training epoch: 30, Training loss: 0.7952, Train accuracy: 0.8967, Test accuracy: 0.7478\n",
      "Training epoch: 31, Training loss: 0.7855, Train accuracy: 0.9036, Test accuracy: 0.7557\n",
      "Training epoch: 32, Training loss: 0.7715, Train accuracy: 0.9121, Test accuracy: 0.7567\n",
      "Training epoch: 33, Training loss: 0.7681, Train accuracy: 0.9150, Test accuracy: 0.7562\n",
      "Training epoch: 34, Training loss: 0.7597, Train accuracy: 0.9186, Test accuracy: 0.7567\n",
      "Training epoch: 35, Training loss: 0.7450, Train accuracy: 0.9176, Test accuracy: 0.7567\n",
      "Training epoch: 36, Training loss: 0.7394, Train accuracy: 0.8947, Test accuracy: 0.7407\n",
      "Training epoch: 37, Training loss: 0.7420, Train accuracy: 0.9238, Test accuracy: 0.7492\n",
      "Training epoch: 38, Training loss: 0.7263, Train accuracy: 0.9261, Test accuracy: 0.7506\n",
      "Training epoch: 39, Training loss: 0.7179, Train accuracy: 0.9311, Test accuracy: 0.7590\n",
      "Training epoch: 40, Training loss: 0.7036, Train accuracy: 0.9326, Test accuracy: 0.7567\n",
      "Training epoch: 41, Training loss: 0.6992, Train accuracy: 0.9309, Test accuracy: 0.7482\n",
      "Training epoch: 42, Training loss: 0.6908, Train accuracy: 0.9408, Test accuracy: 0.7553\n",
      "Training epoch: 43, Training loss: 0.6830, Train accuracy: 0.9434, Test accuracy: 0.7529\n",
      "Training epoch: 44, Training loss: 0.6694, Train accuracy: 0.9420, Test accuracy: 0.7539\n",
      "Training epoch: 45, Training loss: 0.6746, Train accuracy: 0.9489, Test accuracy: 0.7529\n",
      "Training epoch: 46, Training loss: 0.6562, Train accuracy: 0.9472, Test accuracy: 0.7586\n",
      "Training epoch: 47, Training loss: 0.6485, Train accuracy: 0.9538, Test accuracy: 0.7647\n",
      "Training epoch: 48, Training loss: 0.6464, Train accuracy: 0.9566, Test accuracy: 0.7586\n",
      "Training epoch: 49, Training loss: 0.6325, Train accuracy: 0.9567, Test accuracy: 0.7478\n",
      "Training epoch: 50, Training loss: 0.6259, Train accuracy: 0.9601, Test accuracy: 0.7604\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    writer = tf.summary.FileWriter(\"./graphs/cnn\", tf.get_default_graph())\n",
    "    n_batches = int(x_train.shape[0] / BATCH_SIZE)\n",
    "    \n",
    "    for epoch in range(EPOCHES):\n",
    "        total_loss = 0\n",
    "        for x_batch, y_batch in get_batch(x_train, y_train):\n",
    "            _, l = sess.run([optimizer, loss],\n",
    "                            feed_dict={inputs: x_batch, \n",
    "                                       targets: y_batch})\n",
    "            total_loss += l\n",
    "        \n",
    "        train_corrects = sess.run(accuracy, feed_dict={inputs: x_train, targets: y_train})\n",
    "        train_acc = train_corrects / x_train.shape[0]\n",
    "        cnn_train_accuracy.append(train_acc)\n",
    "        \n",
    "        test_corrects = sess.run(accuracy, feed_dict={inputs: x_test, targets: y_test})\n",
    "        test_acc = test_corrects / x_test.shape[0]\n",
    "        cnn_test_accuracy.append(test_acc)\n",
    "        \n",
    "        print(\"Training epoch: {}, Training loss: {:.4f}, Train accuracy: {:.4f}, Test accuracy: {:.4f}\".format(epoch + 1, \n",
    "                                                                                                                total_loss / n_batches,\n",
    "                                                                                                                train_acc,\n",
    "                                                                                                               test_acc))\n",
    "    \n",
    "    saver.save(sess, \"checkpoints/cnn\")\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1830c56f60>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIOEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x182bbf2f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnn_train_accuracy)\n",
    "plt.plot(cnn_test_accuracy)\n",
    "plt.ylim(ymin=0.5, ymax=1.01)\n",
    "plt.title(\"The accuracy of CNN model\")\n",
    "plt.legend([\"train\", \"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/cnn\n",
      "The LSTM model accuracy on test set: 75.25%\n"
     ]
    }
   ],
   "source": [
    "# 在test上的准确率\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"checkpoints/cnn\")\n",
    "    \n",
    "    total_correct = sess.run(accuracy,\n",
    "                             feed_dict={inputs: x_test, targets: y_test})\n",
    "\n",
    "    print(\"The LSTM model accuracy on test set: {:.2f}%\".format(100 * total_correct / x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在命令行执行tensorboard --logdir=\"./graphs/rnn\" --port 6006可以看到模型的tensorboard\n",
    "\n",
    "<img src=\"images/cnn-tensorboard.png\" style=\"width:500;height:500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CNN multi-channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 清空图\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 我在这里定义了5种filter，每种100个\n",
    "filters_size = [2, 3, 4, 5, 6]\n",
    "num_filters = 100\n",
    "# 超参数\n",
    "BATCH_SIZE = 256\n",
    "EPOCHES = 8\n",
    "LEARNING_RATE = 0.001\n",
    "L2_LAMBDA = 10\n",
    "KEEP_PROB = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"cnn_multichannels\"):\n",
    "    with tf.name_scope(\"placeholders\"):\n",
    "        inputs = tf.placeholder(dtype=tf.int32, shape=(None, 20), name=\"inputs\")\n",
    "        targets = tf.placeholder(dtype=tf.float32, shape=(None, 1), name=\"targets\")\n",
    "    # embeddings\n",
    "    with tf.name_scope(\"embeddings\"):\n",
    "        # static embeddings\n",
    "        static_embedding_matrix = tf.Variable(initial_value=static_embeddings, \n",
    "                                              trainable=False, \n",
    "                                              name=\"static_embedding_matrix\")\n",
    "        static_embed = tf.nn.embedding_lookup(static_embedding_matrix, inputs, name=\"static_embed\")\n",
    "        static_embed_expanded = tf.expand_dims(static_embed, -1, name=\"static_embed_expand\")\n",
    "        \n",
    "        # non-static embeddings\n",
    "        dynamic_embedding_matrix = tf.Variable(tf.random_normal(shape=(VOCAB_SIZE, EMBEDDING_SIZE), stddev=0.1), \n",
    "                                               trainable=True, \n",
    "                                               name=\"dynamic_embedding_matrix\")\n",
    "        dynamic_embed = tf.nn.embedding_lookup(dynamic_embedding_matrix, inputs, name=\"dynamic_embed\")\n",
    "        dynamic_embed_expanded = tf.expand_dims(dynamic_embed, -1, name=\"dynamic_embed_expand\")\n",
    "        \n",
    "        # stack\n",
    "        embed_expanded = tf.concat((static_embed_expanded, dynamic_embed_expanded), axis=-1, name=\"embed_expanded\")\n",
    "    \n",
    "    pooled_outputs = []\n",
    "\n",
    "    # 迭代多个filter\n",
    "    for i, filter_size in enumerate(filters_size):\n",
    "        with tf.name_scope(\"conv_maxpool_%s\" % filter_size):\n",
    "            # 注意这里filter的channel要指定为2\n",
    "            filter_shape = [filter_size, EMBEDDING_SIZE, 2, num_filters]\n",
    "            W = tf.Variable(tf.truncated_normal(filter_shape, mean=0.0, stddev=0.1), name=\"W\")\n",
    "            b = tf.Variable(tf.zeros(num_filters), name=\"b\")\n",
    "\n",
    "            conv = tf.nn.conv2d(input=embed_expanded, \n",
    "                                 filter=W, \n",
    "                                 strides=[1, 1, 1, 1], \n",
    "                                 padding=\"VALID\",\n",
    "                                 name=\"conv\")\n",
    "\n",
    "            # 激活\n",
    "            a = tf.nn.relu(tf.nn.bias_add(conv, b), name=\"activations\")\n",
    "            # 池化\n",
    "            max_pooling = tf.nn.max_pool(value=a, \n",
    "                                    ksize=[1, SENTENCE_LIMIT_SIZE - filter_size + 1, 1, 1],\n",
    "                                    strides=[1, 1, 1, 1],\n",
    "                                   padding=\"VALID\",\n",
    "                                   name=\"max_pooling\")\n",
    "            pooled_outputs.append(max_pooling)\n",
    "        \n",
    "    total_filters = num_filters * len(filters_size)\n",
    "    total_pool = tf.concat(pooled_outputs, 3)\n",
    "    flattend_pool = tf.reshape(total_pool, (-1, total_filters))\n",
    "    \n",
    "    with tf.name_scope(\"dropout\"):\n",
    "        dropout = tf.nn.dropout(flattend_pool, KEEP_PROB)\n",
    "    \n",
    "    with tf.name_scope(\"output\"):\n",
    "        W = tf.get_variable(\"W\", shape=(total_filters, 1), initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b = tf.Variable(tf.zeros(1), name=\"b\")\n",
    "        \n",
    "        logits = tf.add(tf.matmul(dropout, W), b)\n",
    "        predictions = tf.nn.sigmoid(logits, name=\"predictions\")\n",
    "    \n",
    "    with tf.name_scope(\"loss\"):\n",
    "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=targets, logits=logits))\n",
    "        loss = loss + L2_LAMBDA * tf.nn.l2_loss(W)\n",
    "        optimizer = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)\n",
    "    \n",
    "    with tf.name_scope(\"evaluation\"):\n",
    "        correct_preds = tf.equal(tf.cast(tf.greater(predictions, 0.5), tf.float32), targets)\n",
    "        accuracy = tf.reduce_sum(tf.reduce_sum(tf.cast(correct_preds, tf.float32), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi_cnn_train_accuracy = []\n",
    "multi_cnn_test_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1, Training loss: 11.0021, Train accuracy: 0.7970, Test accuracy: 0.6948\n",
      "Training epoch: 2, Training loss: 2.1337, Train accuracy: 0.8079, Test accuracy: 0.6943\n",
      "Training epoch: 3, Training loss: 1.2810, Train accuracy: 0.8131, Test accuracy: 0.7304\n",
      "Training epoch: 4, Training loss: 1.1661, Train accuracy: 0.8056, Test accuracy: 0.7271\n",
      "Training epoch: 5, Training loss: 1.0673, Train accuracy: 0.8533, Test accuracy: 0.7548\n",
      "Training epoch: 6, Training loss: 0.9538, Train accuracy: 0.8877, Test accuracy: 0.7628\n",
      "Training epoch: 7, Training loss: 0.8294, Train accuracy: 0.9218, Test accuracy: 0.7703\n",
      "Training epoch: 8, Training loss: 0.7052, Train accuracy: 0.9447, Test accuracy: 0.7703\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    writer = tf.summary.FileWriter(\"./graphs/multi_cnn\", tf.get_default_graph())\n",
    "    n_batches = int(x_train.shape[0] / BATCH_SIZE)\n",
    "    \n",
    "    for epoch in range(EPOCHES):\n",
    "        total_loss = 0\n",
    "        for x_batch, y_batch in get_batch(x_train, y_train):\n",
    "            _, l = sess.run([optimizer, loss],\n",
    "                            feed_dict={inputs: x_batch, \n",
    "                                       targets: y_batch})\n",
    "            total_loss += l\n",
    "        \n",
    "        train_corrects = sess.run(accuracy, feed_dict={inputs: x_train, targets: y_train})\n",
    "        train_acc = train_corrects / x_train.shape[0]\n",
    "        multi_cnn_train_accuracy.append(train_acc)\n",
    "        \n",
    "        test_corrects = sess.run(accuracy, feed_dict={inputs: x_test, targets: y_test})\n",
    "        test_acc = test_corrects / x_test.shape[0]\n",
    "        multi_cnn_test_accuracy.append(test_acc)\n",
    "        \n",
    "        print(\"Training epoch: {}, Training loss: {:.4f}, Train accuracy: {:.4f}, Test accuracy: {:.4f}\".format(epoch + 1, \n",
    "                                                                                                                total_loss / n_batches,\n",
    "                                                                                                                train_acc,\n",
    "                                                                                                                test_acc))\n",
    "    \n",
    "    saver.save(sess, \"checkpoints/multi_cnn\")\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x182933f438>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niESQwl1EJIL+P7C6ECMXINNIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x183600ff98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(multi_cnn_train_accuracy)\n",
    "plt.plot(multi_cnn_test_accuracy)\n",
    "plt.ylim(ymin=0.5, ymax=1.01)\n",
    "plt.title(\"The accuracy of multi-channel CNN model\")\n",
    "plt.legend([\"train\", \"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/multi_cnn\n",
      "The LSTM model accuracy on test set: 76.93%\n"
     ]
    }
   ],
   "source": [
    "# 在test上的准确率\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"checkpoints/multi_cnn\")\n",
    "    \n",
    "    total_correct = sess.run(accuracy,\n",
    "                             feed_dict={inputs: x_test, targets: y_test})\n",
    "\n",
    "    print(\"The LSTM model accuracy on test set: {:.2f}%\".format(100 * total_correct / x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "290px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
